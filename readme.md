# ğŸ§  RAG Wikipedia QA (Offline)

A fully offline **Retrieval-Augmented Generation (RAG)** system that lets you **query any Wikipedia topic using a local LLM and vector store** â€” with no internet or API keys required.

---

## ğŸš€ Features

âœ… Search any Wikipedia topic and save the content locally  
âœ… Embed saved documents into a local FAISS vector store  
âœ… Ask questions using Retrieval-Augmented Generation (RAG)  
âœ… Runs fully **offline** â€” no API keys, no cloud dependency  
âœ… Lightweight model (`sshleifer/tiny-gpt2`) â€” runs even on CPU  
âœ… CLI interface for easy interaction  
âœ… LangChain deprecation warnings cleaned  

---

## ğŸ—‚ï¸ Folder Structure

RAG-Wikipedia-QA/
â”‚
â”œâ”€â”€ docs/ # Saved Wikipedia text files
â”œâ”€â”€ embeddings/ # FAISS vector DBs saved here
â”œâ”€â”€ rag_wikipedia.py # Main script
â”œâ”€â”€ wiki.png # Image (Step 1 & 2)
â”œâ”€â”€ QA.png # Image (Step 3)
â””â”€â”€ README.md # This file

---

---

## ğŸ”§ How It Works (Step-by-Step)

### âœ… Step 1 â€“ Fetch Wikipedia Content

- User is prompted to enter a topic name (e.g., `India`, `Python programming language`)
- The script fetches the article summary and saves it as a `.txt` file under `/docs`


---

### âœ… Step 2 â€“ Embed Text with FAISS

- Loads the saved `.txt` file
- Splits the text into chunks using LangChainâ€™s `CharacterTextSplitter`
- Embeds the chunks into vectors using Hugging Face embeddings
- Stores them in a FAISS vector database (`.faiss` and `.pkl`) inside `/embeddings`

ğŸ“¸ Screenshot:  
![Step 1 & 2](wiki.png)

---

### âœ… Step 3 â€“ Ask a Question (RAG)

- Prompts user to enter the same filename
- Loads the vector store and retrieves relevant chunks based on the question
- Feeds context + question into a local GPT2 model
- Generates and returns an answer offline

ğŸ“¸ Screenshot:  
![Step 3](QA.png)

---

## ğŸ“¦ Requirements

Install dependencies using:

```bash
pip install -r requirements.txt


ğŸ‘¤ Author
Asif Noushad Sharafudeen
ğŸ”— LinkedIn
ğŸ”— GitHub